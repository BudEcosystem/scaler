---
apiVersion: scaler.bud.studio/v1alpha1
kind: BudAIScaler
metadata:
  name: llm-inference-scaler
  namespace: llm-test
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: llm-inference-sim
  minReplicas: 1
  maxReplicas: 5
  scalingStrategy: BudScaler
  metricsSources:
    - metricSourceType: pod
      targetMetric: "vllm:gpu_cache_usage_perc"
      targetValue: "70"
      path: /metrics
      port: "9000"
  predictionConfig:
    enabled: true
    lookAheadMinutes: 5
    # Use the cache usage metric for time-series prediction
    predictionMetrics:
      - "vllm:gpu_cache_usage_perc"
    # Track seasonal patterns for the same metric
    seasonalMetrics:
      - "vllm:gpu_cache_usage_perc"
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 30
